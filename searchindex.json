{"categories":[{"title":"community","uri":"https://dotsplayground.com/categories/community/"},{"title":"Data Oriented Design","uri":"https://dotsplayground.com/categories/data-oriented-design/"},{"title":"dots","uri":"https://dotsplayground.com/categories/dots/"},{"title":"ecs","uri":"https://dotsplayground.com/categories/ecs/"},{"title":"unity","uri":"https://dotsplayground.com/categories/unity/"}],"posts":[{"content":"Introduction In the previous article in this series, Custom Native Container [Part 3]: Parallel Job Using Min Max, we added support for parallel jobs. But these jobs were limited to writing to a single index of the array. In this article we will remove this limitation from our NativeIntArray by adding support for ParallelWriter. The article assumes basic (C#) multithreading knowledge.\nThe result of the previous article can be found here.\nThe final result of this article can be found here.\n1) ParallelWriter Struct First we must add a ParallelWriter struct within our NativeIntArray struct. This is essentially a new container that only allows writing to the array, but allows multiple threads to do so. The actual write operations are implemented using the Interlocked class. This class provides atomic operations. More information can be found here\n144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200  /* * ... More Code ... */ // Allow parallel writing through NativeIntArray.ParallelWriter in a parallel job. \t// No reading allowed. [NativeContainerIsAtomicWriteOnly] [NativeContainer] unsafe public struct ParallelWriter { // Copy pointer of the full container. [NativeDisableUnsafePtrRestriction] internal void* m_Buffer; internal int m_Length; // Copy the safty handle. The dispose sentinal doesn\u0026#39;t need to be copied as no memory will be allocated within this struct. #if ENABLE_UNITY_COLLECTIONS_CHECKS  internal AtomicSafetyHandle m_Safety; #endif \t// Copy length for convenience  public int Length =\u0026gt; m_Length; public int Increment(int index) { // Increment still needs to safety check for write permissions and index range. #if ENABLE_UNITY_COLLECTIONS_CHECKS  AtomicSafetyHandle.CheckWriteAndThrow(m_Safety); if (index \u0026lt; 0 || index \u0026gt; Length) throw new IndexOutOfRangeException(string.Format(\u0026#34;Index {0} is out of range of \u0026#39;{1}\u0026#39; Length.\u0026#34;, index, Length)); #endif  // Increment is implemented as an atomic operation since it can be incremented by multiple threads at the same time.  return Interlocked.Increment(ref *((int*)m_Buffer + index)); } public int Decrement(int index) { #if ENABLE_UNITY_COLLECTIONS_CHECKS  AtomicSafetyHandle.CheckWriteAndThrow(m_Safety); if (index \u0026lt; 0 || index \u0026gt; Length) throw new IndexOutOfRangeException(string.Format(\u0026#34;Index {0} is out of range of \u0026#39;{1}\u0026#39; Length.\u0026#34;, index, Length)); #endif  return Interlocked.Decrement(ref *((int*)m_Buffer + index)); } public int Add(int index, int value) { #if ENABLE_UNITY_COLLECTIONS_CHECKS  AtomicSafetyHandle.CheckWriteAndThrow(m_Safety); if (index \u0026lt; 0 || index \u0026gt; Length) throw new IndexOutOfRangeException(string.Format(\u0026#34;Index {0} is out of range of \u0026#39;{1}\u0026#39; Length.\u0026#34;, index, Length)); #endif  return Interlocked.Add(ref *((int*)m_Buffer + index), value); } } /* * ... More Code ... */   2) AsParallelWriter We define a function to create a NativeIntArray.ParallelWriter out of our container. Its implementation listed below should be pretty straight forward.\n194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215  /* * ... Previous Code ... */ public ParallelWriter AsParallelWriter() { ParallelWriter writer; #if ENABLE_UNITY_COLLECTIONS_CHECKS  AtomicSafetyHandle.CheckWriteAndThrow(m_Safety); writer.m_Safety = m_Safety; AtomicSafetyHandle.UseSecondaryVersion(ref writer.m_Safety); #endif  writer.m_Buffer = m_Buffer; writer.m_Length = m_Length; return writer; } /* * ... More Code ... */   Usage   Thats all we need to implement parallel writing. To prove that our container is in fact now capable handling multiple writers, lets implement something visually interesting. The job below picks a random index in the container and increments it\u0026rsquo;s value in parallel. Random indices are picked according to a normal distribution thats than drawn to the screen as a bar graph. This results in a Galton board!\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  using Unity.Burst; using Unity.Collections; using Unity.Entities; using Unity.Jobs; using Unity.Mathematics; public class NativeIntArraySystem : SystemBase { [BurstCompile] struct ParallelWriteNormalDistributionJob : IJobParallelFor { public Random random; public NativeIntArray.ParallelWriter array; public void Execute(int index) { // Calculate normal distribution.  double u1 = 1.0 - random.NextDouble(); double u2 = 1.0 - random.NextDouble(); double randomStdNormal = math.sqrt(-2.0 * math.log(u1)) * math.sin(2.0 * math.PI * u2); double randomNormal = (array.Length / 2) + randomStdNormal * (array.Length / 8); // Use the normal distribution to pick an element to increment.  int arrayIndex = math.clamp((int)randomNormal, 0, array.Length - 1); // Use our atomic operation.  array.Increment(arrayIndex); } } protected override void OnUpdate() { NativeIntArray myArray = new NativeIntArray(100, Allocator.TempJob); // Fill myArray with normal distribution values.  JobHandle jobHandle = new ParallelWriteNormalDistributionJob() { random = new Random((uint)UnityEngine.Random.Range(0, int.MaxValue)), array = myArray.AsParallelWriter() }.Schedule(10000, 64); // Run our job a 10000 times in batches of 64 (values chosen randomly).  jobHandle.Complete(); // Draw each element in myArray as a bar graph where it\u0026#39;s value is the height of the bar.  Job.WithName(\u0026#34;DrawBarGraph\u0026#34;) .WithReadOnly(myArray) .WithoutBurst() .WithCode(() =\u0026gt; { for (int i = 0; i \u0026lt; myArray.Length; i++) { float barWidth = 1.0f; float barHeight = (myArray[i] / 40.0f) * 10.0f; DrawBar(new float2(i * barWidth, 0), new float2(barWidth, barHeight)); } }).Run(); myArray.Dispose(); } private void DrawBar(float2 position, float2 size) { UnityEngine.Color color = UnityEngine.Color.red; float3 lowerBound = new float3(position.xy, 0); UnityEngine.Debug.DrawLine(lowerBound, lowerBound + new float3(size.x, 0, 0), color); UnityEngine.Debug.DrawLine(lowerBound, lowerBound + new float3(0, size.y, 0), color); UnityEngine.Debug.DrawLine(lowerBound, lowerBound + new float3(size.xy, 0) , color); lowerBound += new float3(size.xy, 0); UnityEngine.Debug.DrawLine(lowerBound, lowerBound + new float3(-size.x, 0, 0), color); UnityEngine.Debug.DrawLine(lowerBound, lowerBound + new float3(0, -size.y, 0), color); } }   Conclusion This article showed how to add support for ParallelWriter. Normal concurrent data structure design applies, so we can implement our operations using the Interlocked class. One thing to note however is that our container is not a managed object, and can therefor not be locked to a thread. This means that all native containers need to be designed as lock free data structures.\nIn the next part we will look into how we can use the thread index to implement a new lock free data structure to hold any value.\nCustom Native Container [Part 1]: The Basics\nCustom Native Container [Part 2]: Deallocate On Job Completion\nCustom Native Container [Part 3]: Parallel Job Using Min Max\nCustom Native Container [Part 4]: Parallel Job Using ParallelWriter\n","id":0,"section":"posts","summary":"Introduction In the previous article in this series, Custom Native Container [Part 3]: Parallel Job Using Min Max, we added support for parallel jobs. But these jobs were limited to writing to a single index of the array. In this article we will remove this limitation from our NativeIntArray by adding support for ParallelWriter. The article assumes basic (C#) multithreading knowledge.\nThe result of the previous article can be found here.","tags":["dots","ecs","csharp","intermediate","native container"],"title":"Custom Native Container [Part 4]: Parallel Job Using ParallelWriter","uri":"https://dotsplayground.com/2020/03/customnativecontainerpt4/","year":"2020"},{"content":"  Introduction In previous parts of this series we looked into how to create a basic custom native container that can be used with jobs. This article will improve our NativeIntArray container to add support for parallel jobs. This is done by using a pattern where the job is split into ranges and each job is only allowed to operate on this range. This limits the array access to the index passed through Execute(int index). More information about how these jobs are schedualed behind the scenes can be found in the Unity documentation here.\nThe result of the previous article can be found here.\nThe final result of this article can be found here.\n1) Enable Support We add the [NativeContainerSupportsMinMaxWriteRestriction] tag to enable support for this kind of parallel job. We also have to create m_MinIndex and m_MaxIndex variables and initialize them with the entire range of our array. These variables are required for safety checking. Watch out, the naming and order of variables is very important here!\nWe will also use this opportunity to have a quick reminder of what our container roughly looked like: a simple array of integers.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57  using System; using System.Diagnostics; using System.Runtime.InteropServices; using System.Threading; using Unity.Burst; using Unity.Collections; using Unity.Collections.LowLevel.Unsafe; using Unity.Jobs; // This enables support for parallel job exection where each worker thread // is only allowed to operation on a range of indices between min and max. [NativeContainerSupportsMinMaxWriteRestriction] [NativeContainerSupportsDeallocateOnJobCompletion] [NativeContainer] [StructLayout(LayoutKind.Sequential)] public unsafe struct NativeIntArray : IDisposable { [NativeDisableUnsafePtrRestriction] internal void* m_Buffer; internal int m_Length; #if ENABLE_UNITY_COLLECTIONS_CHECKS \t// NativeContainerSupportsMinMaxWriteRestriction expects the passed ranges it can operate on to be checked for safety. \t// The range is passed to the container when an parallel job schedules it\u0026#39;s batch jobs. \tinternal int m_MinIndex;  internal int m_MaxIndex; internal AtomicSafetyHandle m_Safety; [NativeSetClassTypeToNullOnSchedule] internal DisposeSentinel m_DisposeSentinel; #endif  internal Allocator m_AllocatorLabel; public NativeIntArray(int length, Allocator allocator, NativeArrayOptions options = NativeArrayOptions.ClearMemory){ /* More Code */ } static void Allocate(int length, Allocator allocator, out NativeIntArray array) { long size = UnsafeUtility.SizeOf\u0026lt;int\u0026gt;() * (long)length; /* More Code */ array = default(NativeIntArray); array.m_Buffer = UnsafeUtility.Malloc(size, UnsafeUtility.AlignOf\u0026lt;int\u0026gt;(), allocator); array.m_Length = length; array.m_AllocatorLabel = allocator; #if ENABLE_UNITY_COLLECTIONS_CHECKS  // By default the job can operate over the entire range.  array.m_MinIndex = 0;  array.m_MaxIndex = length - 1; DisposeSentinel.Create(out array.m_Safety, out array.m_DisposeSentinel, 1, allocator); #endif  } /* * ... Next Code ... */   2) Range checking The only other change we need to make to the code is to check if we are within range when accessing an element in the array. All other functions that access the array in this container use the [] operator to do so, therefor it is enough to add our range checks to this operator only.\n92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142  /* * ... Previous Code ... */ // Remove calls to this function if safety is disabled. [Conditional(\u0026#34;ENABLE_UNITY_COLLECTIONS_CHECKS\u0026#34;)] private void CheckRangeAccess(int index) { #if ENABLE_UNITY_COLLECTIONS_CHECKS \t// Check if we\u0026#39;re within the range of indices that this parallel batch job operates on. \tif (index \u0026lt; m_MinIndex || index \u0026gt; m_MaxIndex) { if (index \u0026lt; Length \u0026amp;\u0026amp; (m_MinIndex != 0 || m_MaxIndex != Length - 1)) throw new IndexOutOfRangeException(string.Format( \u0026#34;Index {0} is out of restricted IJobParallelFor range [{1}...{2}] in ReadWriteBuffer.\\n\u0026#34; + \u0026#34;ReadWriteBuffers are restricted to only read \u0026amp; write the element at the job index. \u0026#34; + \u0026#34;You can use double buffering strategies to avoid race conditions due to \u0026#34; + \u0026#34;reading \u0026amp; writing in parallel to the same elements from a job.\u0026#34;, index, m_MinIndex, m_MaxIndex)); // This is not a parallel job but the index is still out of range. \tthrow new IndexOutOfRangeException(string.Format(\u0026#34;Index {0} is out of range of \u0026#39;{1}\u0026#39; Length.\u0026#34;, index, Length)); } #endif  } public int this[int index] { get { #if ENABLE_UNITY_COLLECTIONS_CHECKS  AtomicSafetyHandle.CheckReadAndThrow(m_Safety); #endif  CheckRangeAccess(index); return UnsafeUtility.ReadArrayElement\u0026lt;int\u0026gt;(m_Buffer, index); } [WriteAccessRequired] set { #if ENABLE_UNITY_COLLECTIONS_CHECKS  AtomicSafetyHandle.CheckWriteAndThrow(m_Safety); #endif  CheckRangeAccess(index); UnsafeUtility.WriteArrayElement(m_Buffer, index, value); } } /* * ... More Code ... */   Usage And that all! We now have added support for deallocation on job completion to our NativeIntArray. An example of this is shown below.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  using Unity.Burst; using Unity.Collections; using Unity.Entities; using Unity.Jobs; using Unity.Mathematics; public class NativeIntArraySystem : SystemBase { [BurstCompile] struct ParallelWriteRangeJob : IJobParallelFor { public Random random; // See the previous part on how to add support for [DeallocateOnJobCompletion]. [DeallocateOnJobCompletion] public NativeIntArray array; public void Execute(int index) { array[index] = random.NextInt(); } } protected override void OnUpdate() { NativeIntArray myArray = new NativeIntArray(1024, Allocator.TempJob); // Fill myArray with random values.  JobHandle jobHandle = new ParallelWriteRangeJob() { random = new Random((uint)UnityEngine.Random.Range(0, int.MaxValue)), array = myArray }.Schedule(myArray.Length, 64, Dependency); // Schedule with a batch size of 64.  Dependency = jobHandle; } }   Conclusion This article showed how to add support for parallel jobs using a pattern where the job is split into ranges. But a limitation of this pattern is that it does not allow for multiple jobs to write to the same index. In the next part we will look how we can make this possible by adding support for ParallelWriter.\nCustom Native Container [Part 1]: The Basics\nCustom Native Container [Part 2]: Deallocate On Job Completion\nCustom Native Container [Part 3]: Parallel Job Using Min Max\nCustom Native Container [Part 4]: Parallel Job Using ParallelWriter\n","id":1,"section":"posts","summary":"Introduction In previous parts of this series we looked into how to create a basic custom native container that can be used with jobs. This article will improve our NativeIntArray container to add support for parallel jobs. This is done by using a pattern where the job is split into ranges and each job is only allowed to operate on this range. This limits the array access to the index passed through Execute(int index).","tags":["dots","ecs","csharp","intermediate","native container"],"title":"Custom Native Container [Part 3]: Parallel Job Using Min Max","uri":"https://dotsplayground.com/2020/03/customnativecontainerpt3/","year":"2020"},{"content":"Introduction In the previous article in this series, Custom Native Container [Part 1]: The Basics, we looked into how we can create a bare basic custom native container for usage with the job system. In this article we will extend our NativeIntArray container to add support for usage with .WithDeallocateOnJobCompletion and [DeallocateOnJobCompletion].\nThe result of the previous article can be found here.\nThe final result of this article can be found here.\n1) Enable Support To enable support for deallocation on job completion we must add the [NativeContainerSupportsDeallocateOnJobCompletion] attribute to our container struct. We will also use this opportunity to have a quick reminder of what our container roughly looked like: a simple array of integers.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  using System; using System.Diagnostics; using System.Runtime.InteropServices; using System.Threading; using Unity.Burst; using Unity.Collections; using Unity.Collections.LowLevel.Unsafe; using Unity.Jobs; // Enable support for \u0026#34;.WithDeallocateOnJobCompletion\u0026#34; and \u0026#34;[DeallocateOnJobCompletion]\u0026#34;. [NativeContainerSupportsDeallocateOnJobCompletion] [NativeContainer] [StructLayout(LayoutKind.Sequential)] public unsafe struct NativeIntArray : IDisposable { [NativeDisableUnsafePtrRestriction] internal void* m_Buffer; internal int m_Length; #if ENABLE_UNITY_COLLECTIONS_CHECKS  internal AtomicSafetyHandle m_Safety; [NativeSetClassTypeToNullOnSchedule] internal DisposeSentinel m_DisposeSentinel; #endif  internal Allocator m_AllocatorLabel; public NativeIntArray(int length, Allocator allocator, NativeArrayOptions options = NativeArrayOptions.ClearMemory) { /* More Code */ } static void Allocate(int length, Allocator allocator, out NativeIntArray array) { long size = UnsafeUtility.SizeOf\u0026lt;int\u0026gt;() * (long)length; /* More Code */ array = default(NativeIntArray); // Allocate memory for our buffer.  array.m_Buffer = UnsafeUtility.Malloc(size, UnsafeUtility.AlignOf\u0026lt;int\u0026gt;(), allocator); array.m_Length = length; array.m_AllocatorLabel = allocator; /* More Code */ } /* More Code */   2) JobHandle Dispose Next we will add a new dispose function to our container struct. This dispose function will not deallocate our container immediately, but will instead return a job handle that can be scheduled later. This is how deallocate on job completion works, by scheduling another job to do the cleanup once our job is completed.\n121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155  /* * ... More Code ... */ public unsafe JobHandle Dispose(JobHandle inputDeps) { #if ENABLE_UNITY_COLLECTIONS_CHECKS  // DisposeSentinel needs to be cleared on the main thread.  DisposeSentinel.Clear(ref m_DisposeSentinel); #endif  // Create a job to dispose of our container and pass a copy of our pointer to it.  NativeCustomArrayDisposeJob disposeJob = new NativeCustomArrayDisposeJob() { Data = new NativeCustomArrayDispose() { m_Buffer = m_Buffer, m_AllocatorLabel = m_AllocatorLabel } }; JobHandle result = disposeJob.Schedule(inputDeps); #if ENABLE_UNITY_COLLECTIONS_CHECKS  AtomicSafetyHandle.Release(m_Safety); #endif  m_Buffer = null; m_Length = 0; return result; } /* * ... More Code ... */   3) NativeCustomArrayDisposeJob And NativeCustomArrayDispose As you may have noticed, inside our Dispose function we make use of two new structs. These need to be defined outside out container struct. NativeCustomArrayDispose is used to hold a copy of our container pointer and NativeCustomArrayDisposeJob will call Dispose. Whenever the job gets scheduled, it will internally make sure that no other job is reading or writing to our container.\n150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177  /* * ... More Code ... */ [NativeContainer] internal unsafe struct NativeCustomArrayDispose { // Relax the pointer safety so jobs can schedule with this struct. [NativeDisableUnsafePtrRestriction] internal void* m_Buffer; internal Allocator m_AllocatorLabel; public void Dispose() { // Free the allocated memory  UnsafeUtility.Free(m_Buffer, m_AllocatorLabel); } } [BurstCompile] internal struct NativeCustomArrayDisposeJob : IJob { internal NativeCustomArrayDispose Data; public void Execute() { Data.Dispose(); } }   Usage And that is it! We now have added support for parallel jobs to our NativeIntArray. An example of this is shown below.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  using Unity.Burst; using Unity.Collections; using Unity.Entities; using Unity.Jobs; using Unity.Mathematics; public class NativeIntArraySystem : SystemBase { protected override void OnUpdate() { NativeIntArray myArray = new NativeIntArray(100, Allocator.TempJob); Job.WithName(\u0026#34;NativeIntArrayJob\u0026#34;) .WithDeallocateOnJobCompletion(myArray) .WithCode(() =\u0026gt; { for (int i = 0; i \u0026lt; myArray.Length; i++) myArray.Increment(i); }).Run(); } }   Conclusion This article showed how to add support for .WithDeallocateOnJobCompletion and [DeallocateOnJobCompletion]. In the next part(s) we will continue to add features to our NativeIntArray by supporting parallel jobs.\nCustom Native Container [Part 1]: The Basics\nCustom Native Container [Part 2]: Deallocate On Job Completion\nCustom Native Container [Part 3]: Parallel Job Using Min Max\nCustom Native Container [Part 4]: Parallel Job Using ParallelWriter\n","id":2,"section":"posts","summary":"Introduction In the previous article in this series, Custom Native Container [Part 1]: The Basics, we looked into how we can create a bare basic custom native container for usage with the job system. In this article we will extend our NativeIntArray container to add support for usage with .WithDeallocateOnJobCompletion and [DeallocateOnJobCompletion].\nThe result of the previous article can be found here.\nThe final result of this article can be found here.","tags":["dots","ecs","csharp","intermediate","native container"],"title":"Custom Native Container [Part 2]: Deallocate On Job Completion","uri":"https://dotsplayground.com/2020/03/customnativecontainerpt2/","year":"2020"},{"content":"Introduction Native containers are used for data communication between jobs. Unity already provides a set of native containers in their Collections package, such as NativeList, NativeQueue, NativeHashMap, etc. But when you need something more custom, you can write your own native container.\nIn this article we will write such a custom container that can be used with jobs. In subsequent articles we will look into adding more advanced features to this container such as adding support for parallel jobs. These articles will not be about how to write a good container type, but rather will seek to demonstrate all the features that can be implemented when writing a custom native container. This article expects basic knowledge of pointers and memory management.\nThe final result of this article can be found here.\nNativeIntArray The container we will be implementing is called NativeIntArray. It is a fixed size array of integers, essentially the same as NativeArray\u0026lt;int\u0026gt;. We will purposely use such a simple example so we can focus on the actual native container implementation. The basic structure of this container is shown below. We will override parts of it to turn into a native container.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  // We will be working with pointers, so our struct needs to be unsafe. public unsafe struct NativeIntArray { internal void* m_Buffer; // Array to hold our integers.  internal int m_Length; public NativeIntArray(int length) { /* Allocate memory... */ } public int this[int index] // Getter and setter using NativeIntArray[index].  { get { return *((int*)m_Buffer + index); } set { *((int*)m_Buffer + index) = value; } } public int Increment(int index) { return ++this[index]; } public int Decrement(int index) { return --this[index]; } public int Add(int index, int value) { return (this[index] += value); } public int Length =\u0026gt; m_Length; }   1) Member Variables Lets first define all the member variables and some of the attributes to turn our struct into a native container. The naming and order of variables is very important here! Make sure to copy it exactly so you do not get weird results. The rest of the code is explained through comments. Do not be afraid if you do not understand what each line does exactly, having a rough idea of what each part does is more important.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  using System; using System.Diagnostics; using System.Runtime.InteropServices; using System.Threading; using Unity.Burst; using Unity.Collections; using Unity.Collections.LowLevel.Unsafe; using Unity.Jobs; // Needed to mark as a native container. [NativeContainer] // Ensure our memory layout is the same as the order of our variables. [StructLayout(LayoutKind.Sequential)] public unsafe struct NativeIntArray : IDisposable { // Relax the pointer safety so jobs can schedule with this container. [NativeDisableUnsafePtrRestriction] internal void* m_Buffer; internal int m_Length; // This macro makes sure safety features can be disabled for better performance. #if ENABLE_UNITY_COLLECTIONS_CHECKS  // Handle to tell if operations such as reading and writing can be performed safely.  internal AtomicSafetyHandle m_Safety; // Handle to tell if the container has been disposed.  // This is a managed object. It can be passed along as the job can\u0026#39;t dispose the container,  // but needs to be (re)set to null on schedule to prevent job access to a managed object. [NativeSetClassTypeToNullOnSchedule] internal DisposeSentinel m_DisposeSentinel; #endif  // Keep track of which memory was allocated (Allocator.Temp/TempJob/Persistent).  internal Allocator m_AllocatorLabel; /* * ... Next Code ... */   2) Allocating Memory Next we will write out constructor and Allocate function. The constructor will use the Allocate function to allocate memory for our buffer. The code is again explained through added comments.\n30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84  /* * ... Previous Code ... */ public NativeIntArray(int length, Allocator allocator, NativeArrayOptions options = NativeArrayOptions.ClearMemory) { Allocate(length, allocator, out this); // Set the memory block to 0 if requested.  if ((options \u0026amp; NativeArrayOptions.ClearMemory) == NativeArrayOptions.ClearMemory) UnsafeUtility.MemClear(m_Buffer, (long)length * UnsafeUtility.SizeOf\u0026lt;int\u0026gt;()); } static void Allocate(int length, Allocator allocator, out NativeIntArray array) { // Calculate how many bytes are needed.  long size = UnsafeUtility.SizeOf\u0026lt;int\u0026gt;() * (long)length; // Check if this is a valid allocation. #if ENABLE_UNITY_COLLECTIONS_CHECKS  if (allocator \u0026lt;= Allocator.None) throw new ArgumentException(\u0026#34;Allocator must be Temp, TempJob or Persistent\u0026#34;, nameof(allocator)); if (length \u0026lt; 0) throw new ArgumentOutOfRangeException(nameof(length), \u0026#34;Length must be \u0026gt;= 0\u0026#34;); if (size \u0026gt; int.MaxValue) throw new ArgumentOutOfRangeException(nameof(length), $\u0026#34;Length * sizeof(int) cannot exceed {(object)int.MaxValue} bytes\u0026#34;); // There are other checks you might want to perform when working with templated containers.  /* if (!UnsafeUtility.IsBlittable\u0026lt;T\u0026gt;()) throw new ArgumentException(string.Format(\u0026#34;{0} used in NativeCustomArray\u0026lt;{0}\u0026gt; must be blittable\u0026#34;, typeof(T))); if (!UnsafeUtility.IsValidNativeContainerElementType\u0026lt;T\u0026gt;()) throw new InvalidOperationException($\u0026#34;{typeof(T)} used in NativeCustomArray\u0026lt;{typeof(T)}\u0026gt; must be unmanaged (contain no managed types) and cannot itself be a native container type.\u0026#34;); */ #endif  array = default(NativeIntArray); // Allocate memory for our buffer.  array.m_Buffer = UnsafeUtility.Malloc(size, UnsafeUtility.AlignOf\u0026lt;int\u0026gt;(), allocator); array.m_Length = length; array.m_AllocatorLabel = allocator; #if ENABLE_UNITY_COLLECTIONS_CHECKS  // Create a dispose sentinel to track memory leaks.  // An atomic safety handle is also created automatically.  DisposeSentinel.Create(out array.m_Safety, out array.m_DisposeSentinel, 1, allocator); #endif  } /* * ... Next Code ... */   3) Read/Write Access Now we can finally write the functionality to change values in our array. The code for this is pretty straight forward, if not simpler than the original.\n78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112  /* * ... Previous Code ... */ public int this[int index] { get { #if ENABLE_UNITY_COLLECTIONS_CHECKS  AtomicSafetyHandle.CheckReadAndThrow(m_Safety); #endif  return UnsafeUtility.ReadArrayElement\u0026lt;int\u0026gt;(m_Buffer, index); } [WriteAccessRequired] set { #if ENABLE_UNITY_COLLECTIONS_CHECKS  AtomicSafetyHandle.CheckWriteAndThrow(m_Safety); #endif  UnsafeUtility.WriteArrayElement(m_Buffer, index, value); } } public int Increment(int index) { return ++this[index]; } public int Decrement(int index) { return --this[index]; } public int Add(int index, int value) { return (this[index] += value); } public int Length =\u0026gt; m_Length; /* * ... Next Code ... */   4) Disposing There is one last thing we must not forget before we can use our container, and that is Dispose. Dispose can be called to cleanup an free our memory after we are done with our container.\n106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124  /* * ... Previous Code ... */ public void Dispose() { #if ENABLE_UNITY_COLLECTIONS_CHECKS  if (!UnsafeUtility.IsValidAllocator(m_AllocatorLabel)) throw new InvalidOperationException(\u0026#34;The NativeArray can not be Disposed because it was not allocated with a valid allocator.\u0026#34;); DisposeSentinel.Dispose(ref m_Safety, ref m_DisposeSentinel); #endif  // Free the allocated memory and reset our variables.  UnsafeUtility.Free(m_Buffer, m_AllocatorLabel); m_Buffer = null; m_Length = 0; } }   Usage That is it! We now have created a NativeIntArray that can be used with jobs like below.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  using Unity.Burst; using Unity.Collections; using Unity.Entities; using Unity.Jobs; using Unity.Mathematics; public class NativeIntArraySystem : SystemBase { protected override void OnUpdate() { NativeIntArray myArray = new NativeIntArray(100, Allocator.TempJob); Job.WithName(\u0026#34;NativeIntArrayJob\u0026#34;).WithCode(() =\u0026gt; { for (int i = 0; i \u0026lt; myArray.Length; i++) myArray.Increment(i); }).Run(); myArray.Dispose(); } }   Conclusion This article showed all the steps involved to create a bare basic native container. But you might have already noticed that a few very useful features are missing. For instance .WithDeallocateOnJobCompletion and [DeallocateOnJobCompletion] will throw an error that our container does not support this incredibly useful feature. We will implement missing features in the next parts of this series:\nCustom Native Container [Part 1]: The Basics\nCustom Native Container [Part 2]: Deallocate On Job Completion\nCustom Native Container [Part 3]: Parallel Job Using Min Max\nCustom Native Container [Part 4]: Parallel Job Using ParallelWriter\n","id":3,"section":"posts","summary":"Introduction Native containers are used for data communication between jobs. Unity already provides a set of native containers in their Collections package, such as NativeList, NativeQueue, NativeHashMap, etc. But when you need something more custom, you can write your own native container.\nIn this article we will write such a custom container that can be used with jobs. In subsequent articles we will look into adding more advanced features to this container such as adding support for parallel jobs.","tags":["dots","ecs","csharp","intermediate","native container"],"title":"Custom Native Container [Part 1]: The Basics","uri":"https://dotsplayground.com/2020/03/customnativecontainerpt1/","year":"2020"},{"content":"Introduction Knowing how the Unity editor can support you while developing with DOTS is important to speed up the workflow and get debugging information. In this post I will go over what editor features are available for DOTS.\nTo follow along with this post you will needed the following packages.\n Entities: Installing this package and its dependencies will add everything needed to develop with DOTS, such as the burst compiler and job system. DOTS Editor: While optional, this package will add extra editor features for DOTS which will be covered here.  Entity Debugger Can be found under: Window \u0026gt; Analysis \u0026gt; Entity Debugger\n  The entity debugger gives information about the state of the world. It can show you which entities exist, what components they contain, which systems are running on them and which chunks are used. We will go over each part of the entity debugger.\n1. World selection:\nAllows you to select the world to show the containing entities and systems of. You can select Show Full Player Loop to show all worlds and Show Inactive Systems to also show systems that are not running.\n2. System details:\nThis section will allow you to view all system groups and the systems they contain. Notice that systems are listed in order of execution.\nFor each system it gives useful performance information in milliseconds spend on the main thread. You can also disable individual systems to prevent them from running. Selecting a system will show you the entities and components the system runs on, and allows you to view chunk information.\n3. Entity inspector:\nThis shows you all the entities that match the specified system query.\nNotice that components are colored based on read only, read write or subtractive (can not contain), but expect this to be expanded on in the future as currently not all query types have a color code.\nSelecting an entity will show you its component values in the inspector, shown here in the image on the right.\n4. Chunk info:\nChunks in DOTS can be very confusing at first, so to properly explain this section I will first give an simplified explanation of chunks. A chunk is a pre-allocated 16kB block of memory, which has an archetype that defines which components are in the chunk. Based on this the chunk calculates how many entities of this archetype it can hold. When entities are added they are put in the chunk until its full at which point a new chunk is created.\nThe chunk info section shows you how many archetypes match a system query and how many chunks each archetype has. At the bottom it than shows how full these chunks are in a histogram.\n  In this image we match 1 archetype which has 3 chunks. A chunk of this archetype can hold 104 entities. 2 chunks are currently full (bar on the right) and 1 chunk holds 13 entities (bar on the left).\nLive Link Mode Can be found under: DOTS \u0026gt; Live Link Mode\n  Live link allows to convert to DOTS while in edit mode. For live link to work you need to add your objects in a subscene: Hierarchy \u0026gt; Right click \u0026gt; New SubScene From Selection. Selecting an object in the subscene will you its ECS components, and the object can now be found in the entity debugger. Keeping the subscene open during play mode will now also allow you to make changes to the entity without restarting.\nThere are two scene view modes for live link. SceneView: Live Game State makes the scene view show the final converted result in edit mode turning the scene into a hybrid rendered scene. SceneView: Editing State will instead keep the editor renderer and not apply the full conversion. This mode will renderer gizmos, but any changes to the entity that happen at conversion will not be applied.\nBurst Inspector Can be found under: Jobs \u0026gt; Burst \u0026gt; Open Inspector...\n  The burst inspector is a useful tool for low level performance optimizations. Most people will not be able or need to read the compiler output. However the LLVM Optimization Diagnostics can still be interesting to look at. It gives compiler info in a more human readable manner, which can be used to for instance check if your code is getting vectorized.\n  Here you can see that the compiler marked line 35 as unable to vectorize.\n  After a change in the code line 35 is marked as vectorized.\nDOTS Compiler Can be found under: DOTS \u0026gt; DOTS Compiler \u0026gt; Open Inspector...\n  The DOTS Compiler can show DOTS generated code. This means its able to show you the code generated when using the [GenerateAuthoringComponent] tag.\nOthers To further control the compilation process you can enable and disable multiple setting having to do with debugging and safety under Jobs. These speak for themselves so I will not be going in depth any further.\n  To speed up the load time when pressing play in the editor, you can disable scene and domain reload under: Edit \u0026gt; Player Settings \u0026gt; Editor \u0026gt; Enter Play Mode Settings. This is not directly connected to DOTS in any way. But its main downsides largely do not apply to DOTS code, while still giving you the benefits of improved speed. For more information see the documentation.\n","id":4,"section":"posts","summary":"Introduction Knowing how the Unity editor can support you while developing with DOTS is important to speed up the workflow and get debugging information. In this post I will go over what editor features are available for DOTS.\nTo follow along with this post you will needed the following packages.\n Entities: Installing this package and its dependencies will add everything needed to develop with DOTS, such as the burst compiler and job system.","tags":["dots","ecs","csharp","beginner"],"title":"Unity DOTS Editor","uri":"https://dotsplayground.com/2020/02/dotseditor/","year":"2020"},{"content":"The first Meeting In our first meeting we defined what a learning community is for us, which model we are using. Besides this we defined our personal goals and the over arching goal. The later is a tower defense game. It is meant to guide us in a direction to give us fuel for our research and prototypes.\nThe method As method we chose the learning community methodology as the basis for our research. We chose the guided learning community, in which the supervisor takes the role as guide, source validator. Their job is it to ensure the quality of the research sources and generally guiding, leading the group sessions. The guide/ supervisor can be part of the teaching staff or be one of the group. This person can be also one allocated each meeting new. In our case we have chosen for a supervisor from the teaching staff as well as a conversation guide per meeting, who leads the meetings.\nThe community comes together in a set period of time, in our case every week. In this time we are defining goals we want to achieve , such as in normal game development with SCRUM sprints. We then review in our meetings the last weeks work as well as define our individual achievements for the next week. In those meetings we are using a stand up like method, this means we debate the results of each individually, talk about what they have been blocked with and what they would need to progress further.\nThe format itself is quite lose the only constant are the questions: What have you been working on? Have you been blocked with what are you going to do next? What do you need?\nThis allows us for adopting to changes in the learning, hence every week we reevaluate the format of the last week to adjust it for the next week.\nThe individual goals for the first week Jonah:\n Next week goal: Learning basics of DOTS; Creating pong. What\u0026rsquo;s needed: Basic DOTS resources Global goal: Get familiar with how DOTS and ECS work and how to program in it.  Niels:\n Next week goal: Reactive systems; What\u0026rsquo;s needed: Positive vibes Global goal: Learning reactive systems and physics in DOTS.  Robin:\n Next week goal: Learning basics of DOTS; Implementing basic movement. What\u0026rsquo;s needed: Basic DOTS resources Global goal: Composing ECS into gameplay by having the player build towers out of components.  Menno:\n Next week goal: Flow field pathfinding. What\u0026rsquo;s needed: Big data; Global goal: Learning pathfinding and AI planning in DOTS  Pepijn:\n Next week goal: Standard render pipeline working. What\u0026rsquo;s needed: SRP resources Global goal: Have the entire project working with SRP.  Jesse:\n Next week goal: Input system to create player. Shoot some stuff. What\u0026rsquo;s needed: Input system resources. Global goal: Get a good grasp on DOTS and how to make a game with it.  Simon:\n Next week goal: Work on physics system triggers/colliders What\u0026rsquo;s needed: Any research physics. Global goal: How is DOTS implemented in the background and how system groups work.  Maiko:\n Next week goal: Write a system that gets the closest entity to another entity What\u0026rsquo;s needed: / Global goal: Understanding DOTS internals to apply to own framework.  ","id":5,"section":"posts","summary":"The first Meeting In our first meeting we defined what a learning community is for us, which model we are using. Besides this we defined our personal goals and the over arching goal. The later is a tower defense game. It is meant to guide us in a direction to give us fuel for our research and prototypes.\nThe method As method we chose the learning community methodology as the basis for our research.","tags":["dots","physics","education","community","learning"],"title":"First Meeting","uri":"https://dotsplayground.com/2020/02/firstmeeting/","year":"2020"},{"content":"How can we implement interaction between entities? Before we can actually answer that question, we should formulate the actual problem.\nSummary There are two problems in an ECS when it comes to interaction between entities: read and write access. The truth is that interactions do not really exists, they hide the implementation of the underlaying relationship. A relationship is then nothing else than the transformation of data. (More about)\nTo reason about the right tool for creating those transformations, we need to reason about our code and ask ourselves the following five questions:\n What data do we operate on? What is our domain? What is the possible input for our transformation. What is the frequentcy of the data use? What are we actually transfroming? How could our algorithm look like? How often do we perfrom our transfromation?  For infrequent read access we can easily use the ComponentDataFromEntity structure. It allows us array like access to the underlying data. It’s not recommended to use this structure for read access because in this case we give up the guaranteed safety of the C# Job System in a multithreaded environment.\nWhen it comes to write access we should consider to make use of the EnityCommandBuffer. This is a great tool to collect a bunch of commands (actions) we want to perform. The buffer can be invoked immediately or deferred, depending on our needs. In the case of SystemGroups we can use our own CommandBuffer or we can use one of the default ones.\nFor more details follow the rest of this post.\nThe problem When creating interactions between entities we mainly face 2 types of problems:\n  Read Access: Concrete this means we have to read certain properties from a particular entity (object) and react based on this. In terms of games: An Actor needs to query / know some information from another part of the game. For example within a Quest System: Have all tasks been completed?\n  Write access: Concrete this means we have to write certain properties to an particular entity (object).\n  Transformation from Interaction towards Relationships In order to start this transformation we should have a quick look at the first principle of Data Oriented Design:\n Data is not the problem domain. For some, it would seem that data-oriented design is the antithesis of most other programming paradigms because data-oriented design is a technique that does not readily allow the problem domain to enter into the software so readily. It does not recognize the concept of an object in any way, as data is consistently without meaning [\u0026hellip;] The data-oriented design approach doesn’t build the real world problem into the code. This could be seen as a failing of the data oriented approach by veteran object-oriented developers, as many examples of the success of object-oriented design come from being able to bring the human concepts to the machine, then in this middle ground, a solution can be written in this language that is understandable by both human and computer. The data-oriented approach gives up some of the human readability by leaving the problem domain in the design document, but stops the machine from having to handle human concepts at any level by just that same action — Data Orinted Design Book Chapter 1.2\n This helps us to recognize that interactions do not really exists, they hide the implementation of the underlaying relationship. A relationship is nothing else then a transformation of data. In case of an ECS the Entity Manager can be seen as a database and the Entity as a Lookup table key which indexes relationships between components. The systems are just here to interpret those relationships and give them meaning. Therefore, a system should only do one job and do this well. Systems perform transformations of data. This allows us to create generic systems which are decoupled and easy to reuse and as such, we should keep the following in mind:\n One of the main design goals for Data Oriented Design driven application is to focus on reusability through decoupling whenever possible. Thus the Unix philosophy Write programs that do one thing and do it well. Write programs to work together — McIlroy is a good way of expressing what a system should do.\n DOTS or any ECS is built with the idea of relationships in mind. When we are writing systems, we transform data from one state to another to give the data meaning. Therefore systems are defining the meaning of the data relationships. This decoupling gives us the flexibility we need to design complex software such as video games. This allows us to modify the behavior later on, without breaking any dependencies.\nHow do we design Systems? To implement the aforementioned relationships, we have to under take a couple of steps. We have to ask the following questions:\n1. What data transformations are we going to do and on which data?This question should lead to “what components do we need to create this relationship?” We should always be able to give a reason why we need this data.\n2. What is our possible domain? (What kind of inputs do we have?)\nWhen we figure this out, we are able to make the right decision later on and can reason about our code how we implement the relationship?\n3. How often does the data change?To determine how often we change the data, we go through component by component and discuss how often we change it. This is important to pick the right tool later. Knowing those numbers or tendencies is great for reasoning about possible performance bottlenecks and where we could apply optimizations.\n4. What are we actually transforming?\nWriting down the algorithm or the constraints of what we are actually doing with our data is a great solution. In order to pick the right tool based on the planned algorithm, we need to consider the cost of our algorithm.\nWhat does cost mean? It can mean anything from runtime costs to implementation cost. It is important to first establish what the right criteria are. The costs at the end enables us to reason about the code.\nTo pick the right tool, we need to be able to reason about the costs an algorithm costs us. In some case if we take run time performance as measurement it is okay to have a slow algorithm if we do not execute this frequently but if this is not the case another solution should be considered.\n5. How often do we execute the algorithm / transformation?\nBased on the information we have by defining what data we need for the transformation, it’s quite easy to define the frequency of execution. The total number of entities / objects is known at the time of judgment therefore we can guess how often this might run. Besides this, we have discussed how often we are suspecting the data to be changed, which leads to a transparency, which gives a good idea of the costs of this code.\nIMPORTANT: When the data changes, the problem changes. Therefore, we have to properly evaluate with the descriptive method the possible outcome and maybe change the implementation.\nRead Access (ComponentDataFromEntity) In case its required to read from a certain entity, ComponentDataFromEntity is the right tool. This tool allows us to read a specified type (component) of an entity. It is a native container that provides array-like access to components of a specific type, therefore we can easily read the data we need from it. It is a powerful tool to access component data from entities but on the other hand it allows random access and is therefore slow.\nIMPORTANT:\n You can safely read from ComponentDataFromEntity in any Job, but by default, you cannot write to components in the container in parallel Jobs (including IJobForEach\u0026lt;T0\u0026gt; and IJobChunk). If you know that two instances of a parallel Job can never write to the same index in the container, you can disable the restriction on parallel writing by adding NativeDisableParallelForRestrictionAttribute to the ComponentDataFromEntity field definition in the Job struct.\nUnity Documentation\n Example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  //... code [BurstCompile] struct MyJob : IJobForEach\u0026lt;MyCmp,Position\u0026gt;{ [ReadOnly] public ComponentDataFromEntity\u0026lt;Position\u0026gt; data; public void Execute([ReadOnly] ref MyCmp mycmp, [ReadOnly] ref Position pos){ if(!data.Exists(mycmp.Entity)) return; Position mycmppos = data[mycmp.Entity]; //... do some magic  } } ///... protected override JobHandle OnUpdate(...){ var job = new MyJob(){ GetComponentDataFromEntity\u0026lt;Position\u0026gt;(true) // true = read only!  } //... }   Write Access (EntityCommandBuffer) The right tool for changing data (write access) in the ECS is it to make use of the EntityCommandBuffer, in case of an infrequent change of data. In a different context, a more value driven approach (direct change) might be more appropriate. The Buffer allows us to cache commands and they will be then executed afterwards. If the context is working in a multithreaded environment it’s important to let the ``EntityCommandBufferto know about this. This will be done via thisEntityCommandBuffer.Concurrent`.\n1 2 3 4 5 6 7 8  //... code [BurstCompile] struct MyJob : IJobForEach\u0026lt;Target\u0026gt;{ public EntityCommandBuffer.Concurrent buffer; public void Execute(Entity entity, int index,[ReadOnly] ref Target target){ buffer.AddComponent(index,target.Enity,typeof(...)); } }   Important to realize here is that nothing happens till the moment Playback() gets called. It depends on our needs if we want to invoke this immediately after we have created the buffer and filled or deferred through Unity’s default Buffers. Then we need to keep the sync points of a game in mind. We have 3 system groups: InitializationSystemGroup SimulationSystemGroup and PresentationSystemGroup. If we do not specify where we want to add our CommandBuffer, our command buffer will be automatically added to the SimulationSystemGroup. It is possible to create your own.\n1 2 3 4 5 6 7 8 9 10 11 12  //...Code protected override OnCreate(...){ m_buffer = world.GetOrCreateSystem\u0026lt;InitializationEntityCommandBufferSystem\u0026gt;(); } protected override JobHandle OnUpdate(...){ var job = new MyJob(){ buffer = m_buffer.CreateCommandBuffer().ToConcurrent() }.Schedule(this,inputDepends); m_buffer.AddJobHandleForProducer(job); return job; }   Brief Overview of SystemGroups (Default)  InitializationSystemGroup (updated at the end of the nitialization phase of the player loop) SimulationSystemGroup (updated at the end of the Update phase of the player loop) PresentationSystemGroup (updated at the end of the PreLateUpdate phase of the player loop)  All of those groups provide 2 command buffers e.g. BeginPresentationEntityCommandBufferSystem and EndPresentationEntityCommandBufferSystem. This can be used to determine when we want to execute what.\nReferences This page is mainly based on the following Unity talk: Options for Entity interaction - Unite Copenhagen   ","id":6,"section":"posts","summary":"How can we implement interaction between entities? Before we can actually answer that question, we should formulate the actual problem.\nSummary There are two problems in an ECS when it comes to interaction between entities: read and write access. The truth is that interactions do not really exists, they hide the implementation of the underlaying relationship. A relationship is then nothing else than the transformation of data. (More about)\nTo reason about the right tool for creating those transformations, we need to reason about our code and ask ourselves the following five questions:","tags":["esc","DOTS","software engineering","dod","data oriented design","ComponentDataFromEntity"],"title":"How Entites could interact","uri":"https://dotsplayground.com/2019/11/entityinteraction/","year":"2019"},{"content":"The problem Often in games different objects interact with each other, eg. a button opens a door, a child follows its parent etc. With the new ESC system those hierarchies aren\u0026rsquo;t trivial, hierarchies don\u0026rsquo;t really exist natively. So how do we link entities in a hierarchy?\nLinking entities as a group In the new ESC if you translate a GameObject via ConvertToEntity to entities the hierarchy would not be translated into the ESC World. The simple solution to this is called LinkedEntityGroup. This translates the hierarchy to ESC land.\nLinkedEntityGroup is a Buffer which can be used to link the lifetime of entities together. This buffer takes an entity as reference point (root) and when this one gets destroyed all the linked entities get destroyed as well.\nThe following example demonstrates the usage of the LinkedEntityGroup:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  public class LinkedEntityGroupComponent: MonoBehaviour, IConvertGameObjectToEntity { public void Convert (Entity entity, EntityManager dstManager, GameObjectConversionSystem conversionSystem) { var buffer = dstManager.AddBuffer \u0026lt;LinkedEntityGroup\u0026gt; (entity); var children = transform.GetComponentsInChildren \u0026lt;Transform\u0026gt; (); foreach (var child in children) { var childEntity = conversionSystem.GetPrimaryEntity (child.gameObject); buffer.Add (childEntity); } } }   ","id":7,"section":"posts","summary":"The problem Often in games different objects interact with each other, eg. a button opens a door, a child follows its parent etc. With the new ESC system those hierarchies aren\u0026rsquo;t trivial, hierarchies don\u0026rsquo;t really exist natively. So how do we link entities in a hierarchy?\nLinking entities as a group In the new ESC if you translate a GameObject via ConvertToEntity to entities the hierarchy would not be translated into the ESC World.","tags":["dots","ecs","csharp","reference","relation","hybrid"],"title":"Linking entities or entity relationships","uri":"https://dotsplayground.com/2019/11/linkingentities/","year":"2019"}],"tags":[{"title":"beginner","uri":"https://dotsplayground.com/tags/beginner/"},{"title":"community","uri":"https://dotsplayground.com/tags/community/"},{"title":"ComponentDataFromEntity","uri":"https://dotsplayground.com/tags/componentdatafromentity/"},{"title":"csharp","uri":"https://dotsplayground.com/tags/csharp/"},{"title":"data oriented design","uri":"https://dotsplayground.com/tags/data-oriented-design/"},{"title":"dod","uri":"https://dotsplayground.com/tags/dod/"},{"title":"dots","uri":"https://dotsplayground.com/tags/dots/"},{"title":"ecs","uri":"https://dotsplayground.com/tags/ecs/"},{"title":"education","uri":"https://dotsplayground.com/tags/education/"},{"title":"esc","uri":"https://dotsplayground.com/tags/esc/"},{"title":"hybrid","uri":"https://dotsplayground.com/tags/hybrid/"},{"title":"intermediate","uri":"https://dotsplayground.com/tags/intermediate/"},{"title":"learning","uri":"https://dotsplayground.com/tags/learning/"},{"title":"native container","uri":"https://dotsplayground.com/tags/native-container/"},{"title":"physics","uri":"https://dotsplayground.com/tags/physics/"},{"title":"reference","uri":"https://dotsplayground.com/tags/reference/"},{"title":"relation","uri":"https://dotsplayground.com/tags/relation/"},{"title":"software engineering","uri":"https://dotsplayground.com/tags/software-engineering/"}]}